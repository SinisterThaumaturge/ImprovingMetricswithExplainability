{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score.scorer import BERTScorer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from utils import NpEncoder\n",
    "import json\n",
    "from scipy.stats.mstats import gmean\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "from evaluation_utils import evaluate_sentence_level, evaluate_word_level, validate_word_level_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'joeddav/xlm-roberta-large-xnli'\n",
    "num_layers = 16\n",
    "idf_sents = 0\n",
    "scorer = BERTScorer(model_type=model_type, batch_size=64, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Languague pairs for Eval4NLP are ro-en, et-en, de-zh, ru-en\n",
    "SRC_LANG = 'et'\n",
    "TGT_LANG = 'en'\n",
    "SPLIT = 'test21'\n",
    "data_dir = f'data/{SPLIT}/{SRC_LANG}-{TGT_LANG}-{SPLIT}'\n",
    "src = [s.strip() for s in open(f'{data_dir}/{SPLIT}.src').readlines()]\n",
    "tgt = [s.strip() for s in open(f'{data_dir}/{SPLIT}.mt').readlines()]\n",
    "wor = [list(map(int, s.strip().split())) for s in open(f'{data_dir}/{SPLIT}.tgt-tags').readlines()]\n",
    "sen = [float(s.strip()) for s in open(f'{data_dir}/{SPLIT}.da').readlines()]\n",
    "assert len(src) == len(tgt) == len(wor) == len(sen)\n",
    "dataset = {'src': src, 'tgt': tgt, 'word_labels': wor, 'sent_labels': sen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscores ,hyp_explanations, src_explanations = scorer.score(dataset['tgt'], dataset['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"limeresults_{SRC_LANG+TGT_LANG}_16_100.json\") as f:\n",
    "  results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"shap_results_{SRC_LANG+TGT_LANG}.json\") as f:\n",
    "  results_shap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mean(vals, p):\n",
    "    p = float(p)\n",
    "    return np.power(\n",
    "        np.mean(\n",
    "            np.power(\n",
    "                np.array(vals, dtype=complex),\n",
    "                p),\n",
    "            axis=0),\n",
    "        1 / p\n",
    "    ).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.799\n"
     ]
    }
   ],
   "source": [
    "sentence_scores = [ gen_mean([w[1] for w in s['1']],-5) for s in results]\n",
    "sentence_scores = np.nan_to_num(sentence_scores,0)\n",
    "cumscores =  np.add(bertscores[2]*0.2,sentence_scores*0.8)\n",
    "value = evaluate_sentence_level(sen,cumscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(columns=[\"src\",\"tgt\",\"p\",\"w\",\"corr\"])\n",
    "\n",
    "for i in range (-100,101,1):\n",
    "  if i == 0:\n",
    "    continue \n",
    "  p = i/10;\n",
    "  sentence_scores = [ gen_mean([w[1] for w in s['1']],p) for s in results]\n",
    "  sentence_scores = np.nan_to_num(sentence_scores,0)\n",
    "  for i in range(11):\n",
    "      cumscores =  np.add(bertscores[2]*i/10,sentence_scores*(1-i/10))\n",
    "      print(f\"I: {i}: \")\n",
    "      value = evaluate_sentence_level(sen,cumscores)\n",
    "      dataframe = pd.concat([dataframe,pd.DataFrame({\"src\":SRC_LANG, \"tgt\": TGT_LANG, \"p\":p, \"w\":i/10, \"corr\": value},index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get p and w values for themaximum correlation\n",
    "dataframe.iloc[dataframe[\"corr\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot different correlation for different p and w values\n",
    "sns.relplot(x=\"p\", y=\"corr\",hue=\"w\",height=10, data=dataframe.query('w==0|w==0.4 |w==0.5| w==0.6 | w==1'));"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c536765888925113768443a5f369da2580327b8baa13e2b94436c1b0fe296407"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
